{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d549a6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from itertools import combinations\n",
    "from diversity_measures import generalized_diversity, entropy_measure, KW_variance, ia_measure, difficulty_measure\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, recall_score, precision_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e56a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('adult-income.csv')\n",
    "data.replace(['?'], np.nan, inplace=True)\n",
    "data.income = data.income == '>50K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46843478",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.sample(frac=0.7, random_state=123)\n",
    "test_data = data.drop(train_data.index)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0f8ac86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250519_131920\"\n",
      "Preset alias specified: 'good' maps to 'good_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.12.3\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.3.0: Thu Jan  2 20:24:23 PST 2025; root:xnu-11215.81.4~3/RELEASE_ARM64_T8122\n",
      "CPU Count:          8\n",
      "Memory Avail:       1.70 GB / 8.00 GB (21.3%)\n",
      "Disk Space Avail:   40.40 GB / 228.27 GB (17.7%)\n",
      "===================================================\n",
      "Presets specified: ['good']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 100s of the 400s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-05-19 15:19:21,972\tINFO worker.py:1843 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"/Users/ola/Library/CloudStorage/OneDrive-Personal/Dokumenty/licencjat/ensemble-diversity-measures/AutogluonModels/ag-20250519_131920/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Beginning AutoGluon training ... Time limit = 98s\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m AutoGluon will save models to \"/Users/ola/Library/CloudStorage/OneDrive-Personal/Dokumenty/licencjat/ensemble-diversity-measures/AutogluonModels/ag-20250519_131920/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Train Data Rows:    30390\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Train Data Columns: 14\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Label Column:       income\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Selected class <--> label mapping:  class 1 = True, class 0 = False\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tAvailable Memory:                    1596.44 MB\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tTrain Data (Original)  Memory Usage: 14.84 MB (0.9% of available memory)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t\t('int', [])    : 6 | ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', ...]\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t\t('int', [])       : 6 | ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', ...]\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t\t('int', ['bool']) : 1 | ['gender']\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.1s = Fit runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t14 features in original data used to generate 14 features in processed data.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tTrain Data (Processed) Memory Usage: 1.63 MB (0.1% of available memory)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'balanced_accuracy'\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t'NN_TORCH': [{}],\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t'CAT': [{}],\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t'XGB': [{}],\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t'FASTAI': [{}],\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 65.10s of the 97.67s of remaining time.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.15%)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.7935\t = Validation score   (balanced_accuracy)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t2.56s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.94s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 60.07s of the 92.64s of remaining time.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.19%)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.8008\t = Validation score   (balanced_accuracy)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t1.5s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.42s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 57.14s of the 89.71s of remaining time.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.7722\t = Validation score   (balanced_accuracy)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t1.0s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.37s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 55.68s of the 88.25s of remaining time.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.7698\t = Validation score   (balanced_accuracy)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.81s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.36s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 54.44s of the 87.01s of remaining time.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 28.16% memory usage per fold, 56.32%/80.00% total).\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=28.16%)\n",
      "\u001b[36m(_ray_fit pid=29885)\u001b[0m \tRan out of time, early stopping on iteration 596.\n",
      "\u001b[36m(_ray_fit pid=29917)\u001b[0m \tRan out of time, early stopping on iteration 653.\n",
      "\u001b[36m(_ray_fit pid=29929)\u001b[0m \tRan out of time, early stopping on iteration 644.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.7967\t = Validation score   (balanced_accuracy)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t42.71s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 10.76s of the 43.33s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=29935)\u001b[0m \tRan out of time, early stopping on iteration 648.\n",
      "\u001b[36m(_ray_fit pid=29942)\u001b[0m \tRan out of time, early stopping on iteration 666.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.7477\t = Validation score   (balanced_accuracy)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.53s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.38s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 9.79s of the 42.36s of remaining time.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.7463\t = Validation score   (balanced_accuracy)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.5s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.37s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 8.85s of the 41.43s of remaining time.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.40%)\n",
      "\u001b[36m(_ray_fit pid=29954)\u001b[0m Metric balanced_accuracy is not supported by this model - using log_loss instead\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.7737\t = Validation score   (balanced_accuracy)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t9.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.2s\t = Validation runtime\n",
      "\u001b[36m(_ray_fit pid=29958)\u001b[0m Metric balanced_accuracy is not supported by this model - using log_loss instead\u001b[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=29958)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 14)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 97.67s of the 30.67s of remaining time.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.8008\t = Validation score   (balanced_accuracy)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.25s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting 11 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 30.41s of the 30.41s of remaining time.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.17%)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.7986\t = Validation score   (balanced_accuracy)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t1.63s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.32s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 27.36s of the 27.36s of remaining time.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.43%)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.8001\t = Validation score   (balanced_accuracy)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t1.59s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.24s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 24.31s of the 24.31s of remaining time.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.7954\t = Validation score   (balanced_accuracy)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t2.33s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.38s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 21.53s of the 21.53s of remaining time.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.7966\t = Validation score   (balanced_accuracy)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t2.41s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.38s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 18.68s of the 18.67s of remaining time.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 19.04% memory usage per fold, 76.16%/80.00% total).\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=19.04%)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.8123\t = Validation score   (balanced_accuracy)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t8.68s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 8.92s of the 8.92s of remaining time.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.7952\t = Validation score   (balanced_accuracy)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.67s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.4s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 7.79s of the 7.79s of remaining time.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.7946\t = Validation score   (balanced_accuracy)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.39s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 6.78s of the 6.78s of remaining time.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.25%)\n",
      "\u001b[36m(_ray_fit pid=30059)\u001b[0m Metric balanced_accuracy is not supported by this model - using log_loss instead\n",
      "\u001b[36m(_ray_fit pid=30060)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 6)\n",
      "\u001b[36m(_ray_fit pid=30060)\u001b[0m Metric balanced_accuracy is not supported by this model - using log_loss instead\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.7967\t = Validation score   (balanced_accuracy)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t7.17s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.3s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 97.67s of the -1.79s of remaining time.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L2': 1.0}\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.8123\t = Validation score   (balanced_accuracy)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.67s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m AutoGluon training complete, total runtime = 100.22s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 2089.4 rows/s (3799 batch size)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.98s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.62s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t1.0s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.37s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.81s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.36s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t5.61s\t = Training   runtime\n",
      "\u001b[36m(_ray_fit pid=30058)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 7)\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.53s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.38s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.5s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.37s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Metric balanced_accuracy is not supported by this model - using log_loss instead\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tStopping at the best epoch learned earlier - 8.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t3.81s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.25s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.48s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.46s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: RandomForestGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t2.33s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.38s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: RandomForestEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t2.41s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.38s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.04s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: ExtraTreesGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.67s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.4s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.39s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Metric balanced_accuracy is not supported by this model - using log_loss instead\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tStopping at the best epoch learned earlier - 5.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t2.16s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L2': 1.0}\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \t0.67s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Updated best model to \"CatBoost_BAG_L2_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"CatBoost_BAG_L2_FULL\" for predict() and predict_proba().\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Refit complete, total runtime = 15.06s ... Best model: \"CatBoost_BAG_L2_FULL\"\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Enabling decision threshold calibration (calibrate_decision_threshold='auto', metric is valid, problem_type is 'binary')\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Calibrating decision threshold to optimize metric balanced_accuracy | Checking 51 thresholds...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Calibrating decision threshold via fine-grained search | Checking 38 thresholds...\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tBase Threshold: 0.500\t| val: 0.8123\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tBest Threshold: 0.471\t| val: 0.8304\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Updating predictor.decision_threshold from 0.5 -> 0.471\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tThis will impact how prediction probabilities are converted to predictions in binary classification.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tPrediction probabilities of the positive class >0.471 will be predicted as the positive class (True). This can significantly impact metric scores.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tYou can update this value via `predictor.set_decision_threshold`.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m \tYou can calculate an optimal decision threshold on the validation data via `predictor.calibrate_decision_threshold()`.\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/ola/Library/CloudStorage/OneDrive-Personal/Dokumenty/licencjat/ensemble-diversity-measures/AutogluonModels/ag-20250519_131920/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=29821)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                           model  score_holdout  score_val        eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           CatBoost_BAG_L2_FULL       0.835209   0.812289  balanced_accuracy        0.419818            NaN  13.889507                 0.002166                     NaN           0.036182            2       True         14\n",
      "1       WeightedEnsemble_L3_FULL       0.835209   0.812289  balanced_accuracy        0.420403            NaN  14.555634                 0.000585                     NaN           0.666127            3       True         18\n",
      "2           CatBoost_BAG_L1_FULL       0.811085   0.796700  balanced_accuracy        0.010044            NaN   5.613389                 0.010044                     NaN           5.613389            1       True          5\n",
      "3           LightGBM_BAG_L1_FULL       0.807785   0.800766  balanced_accuracy        0.025291            NaN   0.621385                 0.025291                     NaN           0.621385            1       True          2\n",
      "4       WeightedEnsemble_L2_FULL       0.807785   0.800766  balanced_accuracy        0.026274            NaN   0.876103                 0.000983                     NaN           0.254718            2       True          9\n",
      "5   RandomForestGini_BAG_L2_FULL       0.807315   0.795353  balanced_accuracy        0.482055            NaN  16.187305                 0.064403                0.380587           2.333981            2       True         12\n",
      "6     ExtraTreesGini_BAG_L2_FULL       0.806672   0.795184  balanced_accuracy        0.485966            NaN  14.518920                 0.068314                0.401926           0.665596            2       True         15\n",
      "7         LightGBMXT_BAG_L1_FULL       0.806383   0.793507  balanced_accuracy        0.042557            NaN   0.977532                 0.042557                     NaN           0.977532            1       True          1\n",
      "8           LightGBM_BAG_L2_FULL       0.804831   0.800105  balanced_accuracy        0.428158            NaN  14.317473                 0.010506                     NaN           0.464149            2       True         11\n",
      "9   RandomForestEntr_BAG_L2_FULL       0.804423   0.796592  balanced_accuracy        0.474746            NaN  16.265646                 0.057094                0.381041           2.412322            2       True         13\n",
      "10    ExtraTreesEntr_BAG_L2_FULL       0.803403   0.794615  balanced_accuracy        0.478371            NaN  14.403457                 0.060719                0.392293           0.550133            2       True         16\n",
      "11        LightGBMXT_BAG_L2_FULL       0.802081   0.798577  balanced_accuracy        0.432011            NaN  14.332648                 0.014359                     NaN           0.479323            2       True         10\n",
      "12   NeuralNetFastAI_BAG_L1_FULL       0.794153   0.773667  balanced_accuracy        0.027078            NaN   3.809804                 0.027078                     NaN           3.809804            1       True          8\n",
      "13   NeuralNetFastAI_BAG_L2_FULL       0.791244   0.796678  balanced_accuracy        0.439754            NaN  16.012887                 0.022102                     NaN           2.159563            2       True         17\n",
      "14  RandomForestEntr_BAG_L1_FULL       0.783397   0.769773  balanced_accuracy        0.077709       0.362395   0.805975                 0.077709                0.362395           0.805975            1       True          4\n",
      "15  RandomForestGini_BAG_L1_FULL       0.782154   0.772151  balanced_accuracy        0.086449       0.374257   0.995279                 0.086449                0.374257           0.995279            1       True          3\n",
      "16    ExtraTreesGini_BAG_L1_FULL       0.766518   0.747720  balanced_accuracy        0.072743       0.380951   0.530308                 0.072743                0.380951           0.530308            1       True          6\n",
      "17    ExtraTreesEntr_BAG_L1_FULL       0.762903   0.746268  balanced_accuracy        0.075781       0.373804   0.499652                 0.075781                0.373804           0.499652            1       True          7\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t120s\t = DyStack   runtime |\t280s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 280s\n",
      "AutoGluon will save models to \"/Users/ola/Library/CloudStorage/OneDrive-Personal/Dokumenty/licencjat/ensemble-diversity-measures/AutogluonModels/ag-20250519_131920\"\n",
      "Train Data Rows:    34189\n",
      "Train Data Columns: 14\n",
      "Label Column:       income\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = True, class 0 = False\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2280.90 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.70 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'educational-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['gender']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.83 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'balanced_accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 186.59s of the 279.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.67%)\n",
      "\t0.794\t = Validation score   (balanced_accuracy)\n",
      "\t3.5s\t = Training   runtime\n",
      "\t1.2s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 180.23s of the 273.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.69%)\n",
      "\t0.7987\t = Validation score   (balanced_accuracy)\n",
      "\t1.79s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 177.04s of the 270.41s of remaining time.\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.7717\t = Validation score   (balanced_accuracy)\n",
      "\t1.2s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 175.24s of the 268.60s of remaining time.\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.7695\t = Validation score   (balanced_accuracy)\n",
      "\t1.02s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 173.63s of the 266.99s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 18.67% memory usage per fold, 74.69%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=18.67%)\n",
      "\t0.7954\t = Validation score   (balanced_accuracy)\n",
      "\t46.27s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 126.27s of the 219.63s of remaining time.\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.7471\t = Validation score   (balanced_accuracy)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 125.07s of the 218.44s of remaining time.\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.745\t = Validation score   (balanced_accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 124.00s of the 217.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.94%)\n",
      "\t0.7735\t = Validation score   (balanced_accuracy)\n",
      "\t20.88s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 101.54s of the 194.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.50%)\n",
      "\t0.7993\t = Validation score   (balanced_accuracy)\n",
      "\t5.68s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 93.75s of the 187.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.44%)\n",
      "\t0.7933\t = Validation score   (balanced_accuracy)\n",
      "\t30.56s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 61.28s of the 154.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.70%)\n",
      "\t0.7985\t = Validation score   (balanced_accuracy)\n",
      "\t2.88s\t = Training   runtime\n",
      "\t1.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 279.95s of the 149.89s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L1': 0.636, 'NeuralNetTorch_BAG_L1': 0.364}\n",
      "\t0.8045\t = Validation score   (balanced_accuracy)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 11 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 149.48s of the 149.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.16%)\n",
      "\t0.7982\t = Validation score   (balanced_accuracy)\n",
      "\t2.39s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 145.39s of the 145.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.13%)\n",
      "\t0.8002\t = Validation score   (balanced_accuracy)\n",
      "\t2.05s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 141.72s of the 141.71s of remaining time.\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.7988\t = Validation score   (balanced_accuracy)\n",
      "\t3.75s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 137.38s of the 137.38s of remaining time.\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.7997\t = Validation score   (balanced_accuracy)\n",
      "\t3.94s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 132.86s of the 132.86s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 18.47% memory usage per fold, 73.88%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=18.47%)\n",
      "\t0.8134\t = Validation score   (balanced_accuracy)\n",
      "\t9.69s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 122.03s of the 122.03s of remaining time.\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.7966\t = Validation score   (balanced_accuracy)\n",
      "\t0.88s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 120.54s of the 120.53s of remaining time.\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.796\t = Validation score   (balanced_accuracy)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 119.24s of the 119.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.50%)\n",
      "\t0.7972\t = Validation score   (balanced_accuracy)\n",
      "\t22.42s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 95.34s of the 95.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.57%)\n",
      "\t0.7991\t = Validation score   (balanced_accuracy)\n",
      "\t4.45s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 88.66s of the 88.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.79%)\n",
      "\t0.8115\t = Validation score   (balanced_accuracy)\n",
      "\t40.33s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 46.75s of the 46.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.38%)\n",
      "\t0.8006\t = Validation score   (balanced_accuracy)\n",
      "\t3.47s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 279.95s of the 41.25s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L2': 1.0}\n",
      "\t0.8134\t = Validation score   (balanced_accuracy)\n",
      "\t0.77s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 239.61s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1030.6 rows/s (4274 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t1.07s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.77s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.2s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.02s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t6.68s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "Metric balanced_accuracy is not supported by this model - using log_loss instead\n",
      "\tStopping at the best epoch learned earlier - 12.\n",
      "\t6.23s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t0.37s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\t6.96s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t1.93s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L1': 0.636, 'NeuralNetTorch_BAG_L1': 0.364}\n",
      "\t0.41s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t0.53s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t0.53s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t3.75s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t3.94s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\t0.1s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.88s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "Metric balanced_accuracy is not supported by this model - using log_loss instead\n",
      "\tStopping at the best epoch learned earlier - 10.\n",
      "\t4.74s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\t0.4s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetTorch_BAG_L2_FULL ...\n",
      "\t6.53s\t = Training   runtime\n",
      "Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\t1.93s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L2': 1.0}\n",
      "\t0.77s\t = Training   runtime\n",
      "Updated best model to \"CatBoost_BAG_L2_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"CatBoost_BAG_L2_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 40.02s ... Best model: \"CatBoost_BAG_L2_FULL\"\n",
      "Enabling decision threshold calibration (calibrate_decision_threshold='auto', metric is valid, problem_type is 'binary')\n",
      "Calibrating decision threshold to optimize metric balanced_accuracy | Checking 51 thresholds...\n",
      "Calibrating decision threshold via fine-grained search | Checking 38 thresholds...\n",
      "\tBase Threshold: 0.500\t| val: 0.8134\n",
      "\tBest Threshold: 0.477\t| val: 0.8303\n",
      "Updating predictor.decision_threshold from 0.5 -> 0.477\n",
      "\tThis will impact how prediction probabilities are converted to predictions in binary classification.\n",
      "\tPrediction probabilities of the positive class >0.477 will be predicted as the positive class (True). This can significantly impact metric scores.\n",
      "\tYou can update this value via `predictor.set_decision_threshold`.\n",
      "\tYou can calculate an optimal decision threshold on the validation data via `predictor.calibrate_decision_threshold()`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/ola/Library/CloudStorage/OneDrive-Personal/Dokumenty/licencjat/ensemble-diversity-measures/AutogluonModels/ag-20250519_131920\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label='income', eval_metric='balanced_accuracy').fit(\n",
    "    train_data=train_data,\n",
    "    time_limit= 400,\n",
    "    presets='good'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7023610",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor2 = TabularPredictor.load(\"/Users/ola/Library/CloudStorage/OneDrive-Personal/Dokumenty/licencjat/ensemble-diversity-measures/AutogluonModels/ag-20250519_131920\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "334c6134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "score_val",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "eval_metric",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pred_time_val",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fit_time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pred_time_val_marginal",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "fit_time_marginal",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "stack_level",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "can_infer",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "fit_order",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c0ce39e6-3f76-4b5e-a225-0f67a763d9ad",
       "rows": [
        [
         "0",
         "CatBoost_BAG_L2",
         "0.8133866733148158",
         "balanced_accuracy",
         "5.913552761077881",
         "124.60616040229797",
         "0.022495508193969727",
         "9.686992168426514",
         "2",
         "False",
         "17"
        ],
        [
         "1",
         "WeightedEnsemble_L3",
         "0.8133866733148158",
         "balanced_accuracy",
         "5.915234565734863",
         "125.37868237495422",
         "0.0016818046569824219",
         "0.77252197265625",
         "3",
         "False",
         "24"
        ],
        [
         "2",
         "NeuralNetTorch_BAG_L2",
         "0.8115083055171401",
         "balanced_accuracy",
         "6.153625965118408",
         "155.24711799621582",
         "0.26256871223449707",
         "40.32794976234436",
         "2",
         "False",
         "22"
        ],
        [
         "3",
         "WeightedEnsemble_L2",
         "0.8044642312635644",
         "balanced_accuracy",
         "0.559398889541626",
         "36.6455135345459",
         "0.0021941661834716797",
         "0.4050459861755371",
         "2",
         "False",
         "12"
        ],
        [
         "4",
         "LightGBMLarge_BAG_L2",
         "0.8006034836300432",
         "balanced_accuracy",
         "6.528749942779541",
         "118.39153814315796",
         "0.6376926898956299",
         "3.472369909286499",
         "2",
         "False",
         "23"
        ],
        [
         "5",
         "LightGBM_BAG_L2",
         "0.8002287099465075",
         "balanced_accuracy",
         "6.102513313293457",
         "116.96435236930847",
         "0.2114560604095459",
         "2.0451841354370117",
         "2",
         "False",
         "14"
        ],
        [
         "6",
         "RandomForestEntr_BAG_L2",
         "0.7997377817726739",
         "balanced_accuracy",
         "6.406686067581177",
         "118.85806608200073",
         "0.5156288146972656",
         "3.9388978481292725",
         "2",
         "False",
         "16"
        ],
        [
         "7",
         "XGBoost_BAG_L1",
         "0.7993134890641664",
         "balanced_accuracy",
         "0.38480448722839355",
         "5.682477712631226",
         "0.38480448722839355",
         "5.682477712631226",
         "1",
         "False",
         "9"
        ],
        [
         "8",
         "XGBoost_BAG_L2",
         "0.7991185989482362",
         "balanced_accuracy",
         "6.078258991241455",
         "119.37334513664246",
         "0.18720173835754395",
         "4.454176902770996",
         "2",
         "False",
         "21"
        ],
        [
         "9",
         "RandomForestGini_BAG_L2",
         "0.7987862181175931",
         "balanced_accuracy",
         "6.404413223266602",
         "118.66664910316467",
         "0.5133559703826904",
         "3.747480869293213",
         "2",
         "False",
         "15"
        ],
        [
         "10",
         "LightGBM_BAG_L1",
         "0.7987216925442966",
         "balanced_accuracy",
         "0.5359306335449219",
         "1.7856707572937012",
         "0.5359306335449219",
         "1.7856707572937012",
         "1",
         "False",
         "2"
        ],
        [
         "11",
         "LightGBMLarge_BAG_L1",
         "0.7984717502232938",
         "balanced_accuracy",
         "1.2044274806976318",
         "2.8838179111480713",
         "1.2044274806976318",
         "2.8838179111480713",
         "1",
         "False",
         "11"
        ],
        [
         "12",
         "LightGBMXT_BAG_L2",
         "0.7982220874982281",
         "balanced_accuracy",
         "6.222646951675415",
         "117.31200528144836",
         "0.3315896987915039",
         "2.3928370475769043",
         "2",
         "False",
         "13"
        ],
        [
         "13",
         "NeuralNetFastAI_BAG_L2",
         "0.797182552153406",
         "balanced_accuracy",
         "6.145164966583252",
         "137.3377993106842",
         "0.2541077136993408",
         "22.418631076812744",
         "2",
         "False",
         "20"
        ],
        [
         "14",
         "ExtraTreesGini_BAG_L2",
         "0.7965744356891705",
         "balanced_accuracy",
         "6.433232069015503",
         "115.80155897140503",
         "0.5421748161315918",
         "0.8823907375335693",
         "2",
         "False",
         "18"
        ],
        [
         "15",
         "ExtraTreesEntr_BAG_L2",
         "0.7960121353658983",
         "balanced_accuracy",
         "6.4478583335876465",
         "115.58007025718689",
         "0.5568010807037354",
         "0.6609020233154297",
         "2",
         "False",
         "19"
        ],
        [
         "16",
         "CatBoost_BAG_L1",
         "0.7954169155579576",
         "balanced_accuracy",
         "0.047965049743652344",
         "46.26959800720215",
         "0.047965049743652344",
         "46.26959800720215",
         "1",
         "False",
         "5"
        ],
        [
         "17",
         "LightGBMXT_BAG_L1",
         "0.7940302301382823",
         "balanced_accuracy",
         "1.1951842308044434",
         "3.5029261112213135",
         "1.1951842308044434",
         "3.5029261112213135",
         "1",
         "False",
         "1"
        ],
        [
         "18",
         "NeuralNetTorch_BAG_L1",
         "0.7932821065958994",
         "balanced_accuracy",
         "0.17240023612976074",
         "30.557989835739136",
         "0.17240023612976074",
         "30.557989835739136",
         "1",
         "False",
         "10"
        ],
        [
         "19",
         "NeuralNetFastAI_BAG_L1",
         "0.7735258929192296",
         "balanced_accuracy",
         "0.3312861919403076",
         "20.876857042312622",
         "0.3312861919403076",
         "20.876857042312622",
         "1",
         "False",
         "8"
        ],
        [
         "20",
         "RandomForestGini_BAG_L1",
         "0.7717308447108282",
         "balanced_accuracy",
         "0.5176839828491211",
         "1.1969659328460693",
         "0.5176839828491211",
         "1.1969659328460693",
         "1",
         "True",
         "3"
        ],
        [
         "21",
         "RandomForestEntr_BAG_L1",
         "0.769467433365404",
         "balanced_accuracy",
         "0.5072669982910156",
         "1.0205821990966797",
         "0.5072669982910156",
         "1.0205821990966797",
         "1",
         "True",
         "4"
        ],
        [
         "22",
         "ExtraTreesGini_BAG_L1",
         "0.7470855671364871",
         "balanced_accuracy",
         "0.5126609802246094",
         "0.6142578125",
         "0.5126609802246094",
         "0.6142578125",
         "1",
         "True",
         "6"
        ],
        [
         "23",
         "ExtraTreesEntr_BAG_L1",
         "0.7449572570178087",
         "balanced_accuracy",
         "0.4814469814300537",
         "0.5280249118804932",
         "0.4814469814300537",
         "0.5280249118804932",
         "1",
         "True",
         "7"
        ],
        [
         "24",
         "ExtraTreesEntr_BAG_L1_FULL",
         null,
         "balanced_accuracy",
         "0.4814469814300537",
         "0.5280249118804932",
         "0.4814469814300537",
         "0.5280249118804932",
         "1",
         "True",
         "31"
        ],
        [
         "25",
         "RandomForestEntr_BAG_L1_FULL",
         null,
         "balanced_accuracy",
         "0.5072669982910156",
         "1.0205821990966797",
         "0.5072669982910156",
         "1.0205821990966797",
         "1",
         "True",
         "28"
        ],
        [
         "26",
         "ExtraTreesGini_BAG_L1_FULL",
         null,
         "balanced_accuracy",
         "0.5126609802246094",
         "0.6142578125",
         "0.5126609802246094",
         "0.6142578125",
         "1",
         "True",
         "30"
        ],
        [
         "27",
         "RandomForestGini_BAG_L1_FULL",
         null,
         "balanced_accuracy",
         "0.5176839828491211",
         "1.1969659328460693",
         "0.5176839828491211",
         "1.1969659328460693",
         "1",
         "True",
         "27"
        ],
        [
         "28",
         "XGBoost_BAG_L2_FULL",
         null,
         "balanced_accuracy",
         null,
         "27.760971784591675",
         null,
         "0.397845983505249",
         "2",
         "True",
         "45"
        ],
        [
         "29",
         "XGBoost_BAG_L1_FULL",
         null,
         "balanced_accuracy",
         null,
         "0.37426304817199707",
         null,
         "0.37426304817199707",
         "1",
         "True",
         "33"
        ],
        [
         "30",
         "WeightedEnsemble_L3_FULL",
         null,
         "balanced_accuracy",
         null,
         "28.236990928649902",
         null,
         "0.77252197265625",
         "3",
         "True",
         "48"
        ],
        [
         "31",
         "WeightedEnsemble_L2_FULL",
         null,
         "balanced_accuracy",
         null,
         "7.73614501953125",
         null,
         "0.4050459861755371",
         "2",
         "True",
         "36"
        ],
        [
         "32",
         "RandomForestGini_BAG_L2_FULL",
         null,
         "balanced_accuracy",
         null,
         "31.11060667037964",
         "0.5133559703826904",
         "3.747480869293213",
         "2",
         "True",
         "39"
        ],
        [
         "33",
         "RandomForestEntr_BAG_L2_FULL",
         null,
         "balanced_accuracy",
         null,
         "31.3020236492157",
         "0.5156288146972656",
         "3.9388978481292725",
         "2",
         "True",
         "40"
        ],
        [
         "34",
         "NeuralNetTorch_BAG_L2_FULL",
         null,
         "balanced_accuracy",
         null,
         "33.89033079147339",
         null,
         "6.527204990386963",
         "2",
         "True",
         "46"
        ],
        [
         "35",
         "NeuralNetTorch_BAG_L1_FULL",
         null,
         "balanced_accuracy",
         null,
         "6.956835985183716",
         null,
         "6.956835985183716",
         "1",
         "True",
         "34"
        ],
        [
         "36",
         "NeuralNetFastAI_BAG_L2_FULL",
         null,
         "balanced_accuracy",
         null,
         "32.09913492202759",
         null,
         "4.736009120941162",
         "2",
         "True",
         "44"
        ],
        [
         "37",
         "NeuralNetFastAI_BAG_L1_FULL",
         null,
         "balanced_accuracy",
         null,
         "6.228686094284058",
         null,
         "6.228686094284058",
         "1",
         "True",
         "32"
        ],
        [
         "38",
         "LightGBM_BAG_L2_FULL",
         null,
         "balanced_accuracy",
         null,
         "27.892160654067993",
         null,
         "0.5290348529815674",
         "2",
         "True",
         "38"
        ],
        [
         "39",
         "LightGBM_BAG_L1_FULL",
         null,
         "balanced_accuracy",
         null,
         "0.7724788188934326",
         null,
         "0.7724788188934326",
         "1",
         "True",
         "26"
        ],
        [
         "40",
         "LightGBMXT_BAG_L2_FULL",
         null,
         "balanced_accuracy",
         null,
         "27.897175788879395",
         null,
         "0.5340499877929688",
         "2",
         "True",
         "37"
        ],
        [
         "41",
         "LightGBMXT_BAG_L1_FULL",
         null,
         "balanced_accuracy",
         null,
         "1.0652308464050293",
         null,
         "1.0652308464050293",
         "1",
         "True",
         "25"
        ],
        [
         "42",
         "LightGBMLarge_BAG_L2_FULL",
         null,
         "balanced_accuracy",
         null,
         "29.294696807861328",
         null,
         "1.9315710067749023",
         "2",
         "True",
         "47"
        ],
        [
         "43",
         "LightGBMLarge_BAG_L1_FULL",
         null,
         "balanced_accuracy",
         null,
         "1.9277639389038086",
         null,
         "1.9277639389038086",
         "1",
         "True",
         "35"
        ],
        [
         "44",
         "ExtraTreesGini_BAG_L2_FULL",
         null,
         "balanced_accuracy",
         null,
         "28.245516538619995",
         "0.5421748161315918",
         "0.8823907375335693",
         "2",
         "True",
         "42"
        ],
        [
         "45",
         "ExtraTreesEntr_BAG_L2_FULL",
         null,
         "balanced_accuracy",
         null,
         "28.024027824401855",
         "0.5568010807037354",
         "0.6609020233154297",
         "2",
         "True",
         "43"
        ],
        [
         "46",
         "CatBoost_BAG_L2_FULL",
         null,
         "balanced_accuracy",
         null,
         "27.464468955993652",
         null,
         "0.10134315490722656",
         "2",
         "True",
         "41"
        ],
        [
         "47",
         "CatBoost_BAG_L1_FULL",
         null,
         "balanced_accuracy",
         null,
         "6.678036212921143",
         null,
         "6.678036212921143",
         "1",
         "True",
         "29"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 48
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>0.813387</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>5.913553</td>\n",
       "      <td>124.606160</td>\n",
       "      <td>0.022496</td>\n",
       "      <td>9.686992</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.813387</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>5.915235</td>\n",
       "      <td>125.378682</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>0.772522</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetTorch_BAG_L2</td>\n",
       "      <td>0.811508</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>6.153626</td>\n",
       "      <td>155.247118</td>\n",
       "      <td>0.262569</td>\n",
       "      <td>40.327950</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.804464</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.559399</td>\n",
       "      <td>36.645514</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.405046</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMLarge_BAG_L2</td>\n",
       "      <td>0.800603</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>6.528750</td>\n",
       "      <td>118.391538</td>\n",
       "      <td>0.637693</td>\n",
       "      <td>3.472370</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>0.800229</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>6.102513</td>\n",
       "      <td>116.964352</td>\n",
       "      <td>0.211456</td>\n",
       "      <td>2.045184</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestEntr_BAG_L2</td>\n",
       "      <td>0.799738</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>6.406686</td>\n",
       "      <td>118.858066</td>\n",
       "      <td>0.515629</td>\n",
       "      <td>3.938898</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>0.799313</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.384804</td>\n",
       "      <td>5.682478</td>\n",
       "      <td>0.384804</td>\n",
       "      <td>5.682478</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost_BAG_L2</td>\n",
       "      <td>0.799119</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>6.078259</td>\n",
       "      <td>119.373345</td>\n",
       "      <td>0.187202</td>\n",
       "      <td>4.454177</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForestGini_BAG_L2</td>\n",
       "      <td>0.798786</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>6.404413</td>\n",
       "      <td>118.666649</td>\n",
       "      <td>0.513356</td>\n",
       "      <td>3.747481</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.798722</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.535931</td>\n",
       "      <td>1.785671</td>\n",
       "      <td>0.535931</td>\n",
       "      <td>1.785671</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>0.798472</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>1.204427</td>\n",
       "      <td>2.883818</td>\n",
       "      <td>1.204427</td>\n",
       "      <td>2.883818</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>0.798222</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>6.222647</td>\n",
       "      <td>117.312005</td>\n",
       "      <td>0.331590</td>\n",
       "      <td>2.392837</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>0.797183</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>6.145165</td>\n",
       "      <td>137.337799</td>\n",
       "      <td>0.254108</td>\n",
       "      <td>22.418631</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ExtraTreesGini_BAG_L2</td>\n",
       "      <td>0.796574</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>6.433232</td>\n",
       "      <td>115.801559</td>\n",
       "      <td>0.542175</td>\n",
       "      <td>0.882391</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ExtraTreesEntr_BAG_L2</td>\n",
       "      <td>0.796012</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>6.447858</td>\n",
       "      <td>115.580070</td>\n",
       "      <td>0.556801</td>\n",
       "      <td>0.660902</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>0.795417</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.047965</td>\n",
       "      <td>46.269598</td>\n",
       "      <td>0.047965</td>\n",
       "      <td>46.269598</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>0.794030</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>1.195184</td>\n",
       "      <td>3.502926</td>\n",
       "      <td>1.195184</td>\n",
       "      <td>3.502926</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>0.793282</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.172400</td>\n",
       "      <td>30.557990</td>\n",
       "      <td>0.172400</td>\n",
       "      <td>30.557990</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.773526</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.331286</td>\n",
       "      <td>20.876857</td>\n",
       "      <td>0.331286</td>\n",
       "      <td>20.876857</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.771731</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.517684</td>\n",
       "      <td>1.196966</td>\n",
       "      <td>0.517684</td>\n",
       "      <td>1.196966</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.769467</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.507267</td>\n",
       "      <td>1.020582</td>\n",
       "      <td>0.507267</td>\n",
       "      <td>1.020582</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>0.747086</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.512661</td>\n",
       "      <td>0.614258</td>\n",
       "      <td>0.512661</td>\n",
       "      <td>0.614258</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1</td>\n",
       "      <td>0.744957</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.481447</td>\n",
       "      <td>0.528025</td>\n",
       "      <td>0.481447</td>\n",
       "      <td>0.528025</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.481447</td>\n",
       "      <td>0.528025</td>\n",
       "      <td>0.481447</td>\n",
       "      <td>0.528025</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RandomForestEntr_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.507267</td>\n",
       "      <td>1.020582</td>\n",
       "      <td>0.507267</td>\n",
       "      <td>1.020582</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ExtraTreesGini_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.512661</td>\n",
       "      <td>0.614258</td>\n",
       "      <td>0.512661</td>\n",
       "      <td>0.614258</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RandomForestGini_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>0.517684</td>\n",
       "      <td>1.196966</td>\n",
       "      <td>0.517684</td>\n",
       "      <td>1.196966</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XGBoost_BAG_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.760972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.397846</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XGBoost_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.374263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.374263</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>WeightedEnsemble_L3_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.236991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.772522</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>WeightedEnsemble_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.736145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.405046</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RandomForestGini_BAG_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.110607</td>\n",
       "      <td>0.513356</td>\n",
       "      <td>3.747481</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>RandomForestEntr_BAG_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.302024</td>\n",
       "      <td>0.515629</td>\n",
       "      <td>3.938898</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NeuralNetTorch_BAG_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.890331</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.527205</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NeuralNetTorch_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.956836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.956836</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.099135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.736009</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.228686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.228686</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>LightGBM_BAG_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.892161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.529035</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>LightGBM_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.772479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.772479</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>LightGBMXT_BAG_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.897176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.534050</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>LightGBMXT_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.065231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.065231</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>LightGBMLarge_BAG_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.294697</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.931571</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>LightGBMLarge_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.927764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.927764</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ExtraTreesGini_BAG_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.245517</td>\n",
       "      <td>0.542175</td>\n",
       "      <td>0.882391</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ExtraTreesEntr_BAG_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.024028</td>\n",
       "      <td>0.556801</td>\n",
       "      <td>0.660902</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>CatBoost_BAG_L2_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.464469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.101343</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>CatBoost_BAG_L1_FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.678036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.678036</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  score_val        eval_metric  pred_time_val  \\\n",
       "0                CatBoost_BAG_L2   0.813387  balanced_accuracy       5.913553   \n",
       "1            WeightedEnsemble_L3   0.813387  balanced_accuracy       5.915235   \n",
       "2          NeuralNetTorch_BAG_L2   0.811508  balanced_accuracy       6.153626   \n",
       "3            WeightedEnsemble_L2   0.804464  balanced_accuracy       0.559399   \n",
       "4           LightGBMLarge_BAG_L2   0.800603  balanced_accuracy       6.528750   \n",
       "5                LightGBM_BAG_L2   0.800229  balanced_accuracy       6.102513   \n",
       "6        RandomForestEntr_BAG_L2   0.799738  balanced_accuracy       6.406686   \n",
       "7                 XGBoost_BAG_L1   0.799313  balanced_accuracy       0.384804   \n",
       "8                 XGBoost_BAG_L2   0.799119  balanced_accuracy       6.078259   \n",
       "9        RandomForestGini_BAG_L2   0.798786  balanced_accuracy       6.404413   \n",
       "10               LightGBM_BAG_L1   0.798722  balanced_accuracy       0.535931   \n",
       "11          LightGBMLarge_BAG_L1   0.798472  balanced_accuracy       1.204427   \n",
       "12             LightGBMXT_BAG_L2   0.798222  balanced_accuracy       6.222647   \n",
       "13        NeuralNetFastAI_BAG_L2   0.797183  balanced_accuracy       6.145165   \n",
       "14         ExtraTreesGini_BAG_L2   0.796574  balanced_accuracy       6.433232   \n",
       "15         ExtraTreesEntr_BAG_L2   0.796012  balanced_accuracy       6.447858   \n",
       "16               CatBoost_BAG_L1   0.795417  balanced_accuracy       0.047965   \n",
       "17             LightGBMXT_BAG_L1   0.794030  balanced_accuracy       1.195184   \n",
       "18         NeuralNetTorch_BAG_L1   0.793282  balanced_accuracy       0.172400   \n",
       "19        NeuralNetFastAI_BAG_L1   0.773526  balanced_accuracy       0.331286   \n",
       "20       RandomForestGini_BAG_L1   0.771731  balanced_accuracy       0.517684   \n",
       "21       RandomForestEntr_BAG_L1   0.769467  balanced_accuracy       0.507267   \n",
       "22         ExtraTreesGini_BAG_L1   0.747086  balanced_accuracy       0.512661   \n",
       "23         ExtraTreesEntr_BAG_L1   0.744957  balanced_accuracy       0.481447   \n",
       "24    ExtraTreesEntr_BAG_L1_FULL        NaN  balanced_accuracy       0.481447   \n",
       "25  RandomForestEntr_BAG_L1_FULL        NaN  balanced_accuracy       0.507267   \n",
       "26    ExtraTreesGini_BAG_L1_FULL        NaN  balanced_accuracy       0.512661   \n",
       "27  RandomForestGini_BAG_L1_FULL        NaN  balanced_accuracy       0.517684   \n",
       "28           XGBoost_BAG_L2_FULL        NaN  balanced_accuracy            NaN   \n",
       "29           XGBoost_BAG_L1_FULL        NaN  balanced_accuracy            NaN   \n",
       "30      WeightedEnsemble_L3_FULL        NaN  balanced_accuracy            NaN   \n",
       "31      WeightedEnsemble_L2_FULL        NaN  balanced_accuracy            NaN   \n",
       "32  RandomForestGini_BAG_L2_FULL        NaN  balanced_accuracy            NaN   \n",
       "33  RandomForestEntr_BAG_L2_FULL        NaN  balanced_accuracy            NaN   \n",
       "34    NeuralNetTorch_BAG_L2_FULL        NaN  balanced_accuracy            NaN   \n",
       "35    NeuralNetTorch_BAG_L1_FULL        NaN  balanced_accuracy            NaN   \n",
       "36   NeuralNetFastAI_BAG_L2_FULL        NaN  balanced_accuracy            NaN   \n",
       "37   NeuralNetFastAI_BAG_L1_FULL        NaN  balanced_accuracy            NaN   \n",
       "38          LightGBM_BAG_L2_FULL        NaN  balanced_accuracy            NaN   \n",
       "39          LightGBM_BAG_L1_FULL        NaN  balanced_accuracy            NaN   \n",
       "40        LightGBMXT_BAG_L2_FULL        NaN  balanced_accuracy            NaN   \n",
       "41        LightGBMXT_BAG_L1_FULL        NaN  balanced_accuracy            NaN   \n",
       "42     LightGBMLarge_BAG_L2_FULL        NaN  balanced_accuracy            NaN   \n",
       "43     LightGBMLarge_BAG_L1_FULL        NaN  balanced_accuracy            NaN   \n",
       "44    ExtraTreesGini_BAG_L2_FULL        NaN  balanced_accuracy            NaN   \n",
       "45    ExtraTreesEntr_BAG_L2_FULL        NaN  balanced_accuracy            NaN   \n",
       "46          CatBoost_BAG_L2_FULL        NaN  balanced_accuracy            NaN   \n",
       "47          CatBoost_BAG_L1_FULL        NaN  balanced_accuracy            NaN   \n",
       "\n",
       "      fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0   124.606160                0.022496           9.686992            2   \n",
       "1   125.378682                0.001682           0.772522            3   \n",
       "2   155.247118                0.262569          40.327950            2   \n",
       "3    36.645514                0.002194           0.405046            2   \n",
       "4   118.391538                0.637693           3.472370            2   \n",
       "5   116.964352                0.211456           2.045184            2   \n",
       "6   118.858066                0.515629           3.938898            2   \n",
       "7     5.682478                0.384804           5.682478            1   \n",
       "8   119.373345                0.187202           4.454177            2   \n",
       "9   118.666649                0.513356           3.747481            2   \n",
       "10    1.785671                0.535931           1.785671            1   \n",
       "11    2.883818                1.204427           2.883818            1   \n",
       "12  117.312005                0.331590           2.392837            2   \n",
       "13  137.337799                0.254108          22.418631            2   \n",
       "14  115.801559                0.542175           0.882391            2   \n",
       "15  115.580070                0.556801           0.660902            2   \n",
       "16   46.269598                0.047965          46.269598            1   \n",
       "17    3.502926                1.195184           3.502926            1   \n",
       "18   30.557990                0.172400          30.557990            1   \n",
       "19   20.876857                0.331286          20.876857            1   \n",
       "20    1.196966                0.517684           1.196966            1   \n",
       "21    1.020582                0.507267           1.020582            1   \n",
       "22    0.614258                0.512661           0.614258            1   \n",
       "23    0.528025                0.481447           0.528025            1   \n",
       "24    0.528025                0.481447           0.528025            1   \n",
       "25    1.020582                0.507267           1.020582            1   \n",
       "26    0.614258                0.512661           0.614258            1   \n",
       "27    1.196966                0.517684           1.196966            1   \n",
       "28   27.760972                     NaN           0.397846            2   \n",
       "29    0.374263                     NaN           0.374263            1   \n",
       "30   28.236991                     NaN           0.772522            3   \n",
       "31    7.736145                     NaN           0.405046            2   \n",
       "32   31.110607                0.513356           3.747481            2   \n",
       "33   31.302024                0.515629           3.938898            2   \n",
       "34   33.890331                     NaN           6.527205            2   \n",
       "35    6.956836                     NaN           6.956836            1   \n",
       "36   32.099135                     NaN           4.736009            2   \n",
       "37    6.228686                     NaN           6.228686            1   \n",
       "38   27.892161                     NaN           0.529035            2   \n",
       "39    0.772479                     NaN           0.772479            1   \n",
       "40   27.897176                     NaN           0.534050            2   \n",
       "41    1.065231                     NaN           1.065231            1   \n",
       "42   29.294697                     NaN           1.931571            2   \n",
       "43    1.927764                     NaN           1.927764            1   \n",
       "44   28.245517                0.542175           0.882391            2   \n",
       "45   28.024028                0.556801           0.660902            2   \n",
       "46   27.464469                     NaN           0.101343            2   \n",
       "47    6.678036                     NaN           6.678036            1   \n",
       "\n",
       "    can_infer  fit_order  \n",
       "0       False         17  \n",
       "1       False         24  \n",
       "2       False         22  \n",
       "3       False         12  \n",
       "4       False         23  \n",
       "5       False         14  \n",
       "6       False         16  \n",
       "7       False          9  \n",
       "8       False         21  \n",
       "9       False         15  \n",
       "10      False          2  \n",
       "11      False         11  \n",
       "12      False         13  \n",
       "13      False         20  \n",
       "14      False         18  \n",
       "15      False         19  \n",
       "16      False          5  \n",
       "17      False          1  \n",
       "18      False         10  \n",
       "19      False          8  \n",
       "20       True          3  \n",
       "21       True          4  \n",
       "22       True          6  \n",
       "23       True          7  \n",
       "24       True         31  \n",
       "25       True         28  \n",
       "26       True         30  \n",
       "27       True         27  \n",
       "28       True         45  \n",
       "29       True         33  \n",
       "30       True         48  \n",
       "31       True         36  \n",
       "32       True         39  \n",
       "33       True         40  \n",
       "34       True         46  \n",
       "35       True         34  \n",
       "36       True         44  \n",
       "37       True         32  \n",
       "38       True         38  \n",
       "39       True         26  \n",
       "40       True         37  \n",
       "41       True         25  \n",
       "42       True         47  \n",
       "43       True         35  \n",
       "44       True         42  \n",
       "45       True         43  \n",
       "46       True         41  \n",
       "47       True         29  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dlaczego modele L1 itd nie działają?\n",
    "predictor2.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "675e7077",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = predictor2.model_names()\n",
    "model_names.pop(model_names.index('WeightedEnsemble_L2_FULL')) \n",
    "model_names.pop(model_names.index('WeightedEnsemble_L3_FULL')) \n",
    "mdls = model_names[24:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cecf0695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LightGBMXT_BAG_L1_FULL',\n",
       " 'LightGBM_BAG_L1_FULL',\n",
       " 'RandomForestGini_BAG_L1_FULL',\n",
       " 'RandomForestEntr_BAG_L1_FULL',\n",
       " 'CatBoost_BAG_L1_FULL',\n",
       " 'ExtraTreesGini_BAG_L1_FULL',\n",
       " 'ExtraTreesEntr_BAG_L1_FULL',\n",
       " 'NeuralNetFastAI_BAG_L1_FULL',\n",
       " 'XGBoost_BAG_L1_FULL',\n",
       " 'NeuralNetTorch_BAG_L1_FULL',\n",
       " 'LightGBMLarge_BAG_L1_FULL',\n",
       " 'LightGBMXT_BAG_L2_FULL',\n",
       " 'LightGBM_BAG_L2_FULL',\n",
       " 'RandomForestGini_BAG_L2_FULL',\n",
       " 'RandomForestEntr_BAG_L2_FULL',\n",
       " 'CatBoost_BAG_L2_FULL',\n",
       " 'ExtraTreesGini_BAG_L2_FULL',\n",
       " 'ExtraTreesEntr_BAG_L2_FULL',\n",
       " 'NeuralNetFastAI_BAG_L2_FULL',\n",
       " 'XGBoost_BAG_L2_FULL',\n",
       " 'NeuralNetTorch_BAG_L2_FULL',\n",
       " 'LightGBMLarge_BAG_L2_FULL']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f6e6b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb7 = list(combinations(mdls, 7))\n",
    "comb5 = list(combinations(mdls, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a2ae666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LightGBM_BAG_L2_FULL'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdls[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84ea41b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredictor2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_names\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# modele bez FULL nigdy nie działają\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/autogluon/tabular/predictor/predictor.py:2375\u001b[0m, in \u001b[0;36mTabularPredictor.predict\u001b[0;34m(self, data, model, as_pandas, transform_features, decision_threshold)\u001b[0m\n\u001b[1;32m   2373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decision_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2374\u001b[0m     decision_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_threshold\n\u001b[0;32m-> 2375\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_learner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_pandas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecision_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecision_threshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/autogluon/tabular/learner/abstract_learner.py:208\u001b[0m, in \u001b[0;36mAbstractTabularLearner.predict\u001b[0;34m(self, X, model, as_pandas, inverse_transform, transform_features, decision_threshold)\u001b[0m\n\u001b[1;32m    206\u001b[0m     decision_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m    207\u001b[0m X_index \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(X\u001b[38;5;241m.\u001b[39mindex) \u001b[38;5;28;01mif\u001b[39;00m as_pandas \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_multiclass\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform_features\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m problem_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_cleaner\u001b[38;5;241m.\u001b[39mproblem_type_transform \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type\n\u001b[1;32m    212\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m get_pred_from_proba(y_pred_proba\u001b[38;5;241m=\u001b[39my_pred_proba, problem_type\u001b[38;5;241m=\u001b[39mproblem_type, decision_threshold\u001b[38;5;241m=\u001b[39mdecision_threshold)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/autogluon/tabular/learner/abstract_learner.py:189\u001b[0m, in \u001b[0;36mAbstractTabularLearner.predict_proba\u001b[0;34m(self, X, model, as_pandas, as_multiclass, inverse_transform, transform_features)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m transform_features:\n\u001b[1;32m    188\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_features(X)\n\u001b[0;32m--> 189\u001b[0m     y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_trainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_predict_proba(\n\u001b[1;32m    191\u001b[0m     y_pred_proba\u001b[38;5;241m=\u001b[39my_pred_proba, as_pandas\u001b[38;5;241m=\u001b[39mas_pandas, index\u001b[38;5;241m=\u001b[39mX_index, as_multiclass\u001b[38;5;241m=\u001b[39mas_multiclass, inverse_transform\u001b[38;5;241m=\u001b[39minverse_transform\n\u001b[1;32m    192\u001b[0m )\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_pred_proba\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py:978\u001b[0m, in \u001b[0;36mAbstractTabularTrainer.predict_proba\u001b[0;34m(self, X, model)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_best()\n\u001b[0;32m--> 978\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_proba_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py:3335\u001b[0m, in \u001b[0;36mAbstractTabularTrainer._predict_proba_model\u001b[0;34m(self, X, model, model_pred_proba_dict)\u001b[0m\n\u001b[1;32m   3334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict_proba_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: pd\u001b[38;5;241m.\u001b[39mDataFrame, model: \u001b[38;5;28mstr\u001b[39m, model_pred_proba_dict: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m-> 3335\u001b[0m     model_pred_proba_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_pred_proba_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_pred_proba_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_pred_proba_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   3337\u001b[0m         model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/autogluon/tabular/trainer/abstract_trainer.py:1253\u001b[0m, in \u001b[0;36mAbstractTabularTrainer.get_model_pred_proba_dict\u001b[0;34m(self, X, models, model_pred_proba_dict, model_pred_time_dict, record_pred_time, use_val_cache)\u001b[0m\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, StackerEnsembleModel):\n\u001b[1;32m   1252\u001b[0m     preprocess_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(infer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, model_pred_proba_dict\u001b[38;5;241m=\u001b[39mmodel_pred_proba_dict)\n\u001b[0;32m-> 1253\u001b[0m     model_pred_proba_dict[model_name] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpreprocess_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1255\u001b[0m     model_pred_proba_dict[model_name] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py:1173\u001b[0m, in \u001b[0;36mAbstractModel.predict_proba\u001b[0;34m(self, X, normalize, record_time, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;124;03mReturns class prediction probabilities of X.\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;124;03mFor binary problems, this returns the positive class label probability as a 1d numpy array.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;124;03m    The prediction probabilities\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;28;01mif\u001b[39;00m record_time \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_proba_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams_aux\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature_scalar\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1176\u001b[0m     y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_temperature_scaling(y_pred_proba)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py:588\u001b[0m, in \u001b[0;36mBaggedEnsembleModel._predict_proba_internal\u001b[0;34m(self, X, normalize, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_child(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    587\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(X, model\u001b[38;5;241m=\u001b[39mmodel, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 588\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_nonadaptive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    590\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_child(model)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py:1173\u001b[0m, in \u001b[0;36mAbstractModel.predict_proba\u001b[0;34m(self, X, normalize, record_time, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;124;03mReturns class prediction probabilities of X.\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;124;03mFor binary problems, this returns the positive class label probability as a 1d numpy array.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;124;03m    The prediction probabilities\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;28;01mif\u001b[39;00m record_time \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_proba_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams_aux\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature_scalar\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1176\u001b[0m     y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_temperature_scaling(y_pred_proba)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/autogluon/core/models/abstract/abstract_model.py:1187\u001b[0m, in \u001b[0;36mAbstractModel._predict_proba_internal\u001b[0;34m(self, X, normalize, **kwargs)\u001b[0m\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1186\u001b[0m     normalize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_pred_probas\n\u001b[0;32m-> 1187\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[1;32m   1189\u001b[0m     y_pred_proba \u001b[38;5;241m=\u001b[39m normalize_pred_probas(y_pred_proba, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/autogluon/tabular/models/lgb/lgb_model.py:361\u001b[0m, in \u001b[0;36mLGBModel._predict_proba\u001b[0;34m(self, X, num_cpus, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, num_cpus\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    359\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 361\u001b[0m     y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(X, num_threads\u001b[38;5;241m=\u001b[39mnum_cpus)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m QUANTILE:\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;66;03m# y_pred_proba is a pd.DataFrame, need to convert\u001b[39;00m\n\u001b[1;32m    364\u001b[0m         y_pred_proba \u001b[38;5;241m=\u001b[39m y_pred_proba\u001b[38;5;241m.\u001b[39mto_numpy()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "predictor2.predict(test_data, model=model_names[0])\n",
    "# modele bez FULL nigdy nie działają"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dad0cb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, ..., False, False, False])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor2.predict(test_data, model=mdls[12]).to_numpy()\n",
    "# po wczytaniu modeli z pliku to nie działa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8c45341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99081850e-01, 9.18148668e-04],\n",
       "       [4.79624033e-01, 5.20375967e-01],\n",
       "       [9.99242902e-01, 7.57073518e-04],\n",
       "       ...,\n",
       "       [6.52624846e-01, 3.47375125e-01],\n",
       "       [7.42681444e-01, 2.57318556e-01],\n",
       "       [9.79509294e-01, 2.04907097e-02]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor2.predict_proba(test_data, model='LightGBM_BAG_L2_FULL').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42d9546f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mdls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4cf238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zapisanie predykcji pstwa i predykcji 0 1\n",
    "pred_prob = []\n",
    "pred = []\n",
    "for mdl in mdls:\n",
    "    pred_prob.append(predictor2.predict_proba(test_data.drop('income', axis = 1), model=mdl).to_numpy())\n",
    "    p1 = predictor2.predict(test_data.drop('income', axis = 1), model=mdl).to_numpy()\n",
    "    pred.append(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e86b2787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"pred_prob1905\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(pred_prob, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98c59d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pred_prob1905\", \"rb\") as fp:   # Unpickling\n",
    "    b = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f246b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pred1905\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(pred, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854e7671",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pred1905\", \"rb\") as fp:   # Unpickling\n",
    "    b = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d445993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = [i for i in range(22)]\n",
    "comb_num = list(combinations(num, 5))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c2c091b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m KW_results\u001b[38;5;241m.\u001b[39mappend(KW_variance(test_data\u001b[38;5;241m.\u001b[39mincome, \u001b[38;5;241m0.5\u001b[39m, pred_prob[comb_num[i][\u001b[38;5;241m0\u001b[39m]], pred_prob[comb_num[i][\u001b[38;5;241m1\u001b[39m]], pred_prob[comb_num[i][\u001b[38;5;241m2\u001b[39m]], pred_prob[comb_num[i][\u001b[38;5;241m3\u001b[39m]], pred_prob[comb_num[i][\u001b[38;5;241m4\u001b[39m]]))\n\u001b[1;32m     12\u001b[0m ia_results\u001b[38;5;241m.\u001b[39mappend(ia_measure(test_data\u001b[38;5;241m.\u001b[39mincome, \u001b[38;5;241m0.5\u001b[39m, pred_prob[comb_num[i][\u001b[38;5;241m0\u001b[39m]], pred_prob[comb_num[i][\u001b[38;5;241m1\u001b[39m]], pred_prob[comb_num[i][\u001b[38;5;241m2\u001b[39m]], pred_prob[comb_num[i][\u001b[38;5;241m3\u001b[39m]], pred_prob[comb_num[i][\u001b[38;5;241m4\u001b[39m]]))\n\u001b[0;32m---> 13\u001b[0m diff_results\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdifficulty_measure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincome\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_prob\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcomb_num\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_prob\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcomb_num\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_prob\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcomb_num\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_prob\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcomb_num\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_prob\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcomb_num\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Dokumenty/licencjat/ensemble-diversity-measures/diversity_measures.py:258\u001b[0m, in \u001b[0;36mdifficulty_measure\u001b[0;34m(y, treshold, *args)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(L):\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y[i] \u001b[38;5;241m==\u001b[39m y_bin[j,i]:\n\u001b[0;32m--> 258\u001b[0m             tmp \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    259\u001b[0m     l\u001b[38;5;241m.\u001b[39mappend(tmp)\n\u001b[1;32m    260\u001b[0m l \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(l)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# zapisanie wartości miar dla komitetów\n",
    "entropy_results = []\n",
    "KW_results = []\n",
    "ia_results = []\n",
    "diff_results = []\n",
    "gd_results = []\n",
    "\n",
    "for i in range(len(comb_num)): \n",
    "    gd_results.append(generalized_diversity(test_data.income, 0.5, pred_prob[comb_num[i][0]], pred_prob[comb_num[i][1]], pred_prob[comb_num[i][2]], pred_prob[comb_num[i][3]], pred_prob[comb_num[i][4]]))\n",
    "    entropy_results.append(entropy_measure(test_data.income, 0.5, pred_prob[comb_num[i][0]], pred_prob[comb_num[i][1]], pred_prob[comb_num[i][2]], pred_prob[comb_num[i][3]], pred_prob[comb_num[i][4]]))\n",
    "    KW_results.append(KW_variance(test_data.income, 0.5, pred_prob[comb_num[i][0]], pred_prob[comb_num[i][1]], pred_prob[comb_num[i][2]], pred_prob[comb_num[i][3]], pred_prob[comb_num[i][4]]))\n",
    "    ia_results.append(ia_measure(test_data.income, 0.5, pred_prob[comb_num[i][0]], pred_prob[comb_num[i][1]], pred_prob[comb_num[i][2]], pred_prob[comb_num[i][3]], pred_prob[comb_num[i][4]]))\n",
    "    diff_results.append(difficulty_measure(test_data.income, 0.5, pred_prob[comb_num[i][0]], pred_prob[comb_num[i][1]], pred_prob[comb_num[i][2]], pred_prob[comb_num[i][3]], pred_prob[comb_num[i][4]]))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc43c854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# głosowanie\n",
    "pred_t = [list(i) for i in zip(*pred)]\n",
    "res = [[] for i in range (len(comb_num))]\n",
    "for i in range(len(comb_num)):\n",
    "    for j in range (len(test_data.income)):\n",
    "        if sum([pred_t[j][comb_num[i][0]], pred_t[j][comb_num[i][1]], pred_t[j][comb_num[i][2]], pred_t[j][comb_num[i][3]], pred_t[j][comb_num[i][4]]]) > 2:\n",
    "            res[i].append(1)\n",
    "        else:\n",
    "            res[i].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f608b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zapisanie wartości metryk\n",
    "scores = []\n",
    "for i in range (len(comb_num)):\n",
    "    scores.append([accuracy_score(test_data.income,res[i]), recall_score(test_data.income,res[i]),precision_score(test_data.income,res[i]), roc_auc_score(test_data.income,res[i]), balanced_accuracy_score(test_data.income,res[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6716ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(scores)\n",
    "df1['gd'] = gd_results\n",
    "df2 = df1.sort_values(by='gd').reset_index(drop=True)\n",
    "df2 = df2.rename(columns={0: \"acc\", 1: \"recall\", 2: \"prec\", 3:'auc', 4: 'bal_acc'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db630433",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d038d67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.plot(1- df2.gd, label = \"1 - gd\")\n",
    "plt.plot(df2.acc, label = 'acc')\n",
    "plt.plot(df2.recall, label = 'recall')\n",
    "plt.plot(df2.prec, label = 'precision')\n",
    "plt.plot(df2.auc, label = 'auc')\n",
    "plt.plot(df2.bal_acc, label = 'bal acc')\n",
    "\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdce763",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a95bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(gd_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc33048",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.model_info('WeightedEnsemble_L3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
